# -*- coding: utf-8 -*-
"""treinamentoModeloFlask.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18r6Op6TAuMKJxqS0U_LPqYdbh3-w8U3A
"""

!pip install scikit-learn==1.5.0

import pandas as pd
import numpy as np
from pandas import DataFrame
import seaborn as sns
from google.colab import drive
import plotly.express as px
import plotly.graph_objects as go
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier, export_graphviz
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
import graphviz
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.ensemble import HistGradientBoostingClassifier
from sklearn.datasets import load_iris
#from googletrans import Translator
import joblib
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import LabelEncoder
from google.colab import files

drive.mount('/content/gdrive/')

data = pd.read_excel("/content/gdrive/My Drive/dados_mestrado/data_cpf_modelo_bsi_evasao.xlsx")

data_unicos = data.drop_duplicates(subset='NOME_PESSOA')

# prompt: printe cada valor único das seguintes colunas de data_unicos: ['ingresso_atual', 'Categoria', 'IsTheyBusinessperson', 'SEXO', 'employee_student']

for column in ['ingresso_atual', 'Categoria', 'Empresario', 'SEXO', 'employee_student']:
  unique_values = data_unicos[column].unique()
  print(f"Unique values for column '{column}':")
  for value in unique_values:
    print(f"\t- {value}")

data.rename(columns={'Empresario':'IsTheyBusinessperson'}, inplace=True)
data_unicos.rename(columns={'Empresario':'IsTheyBusinessperson'}, inplace=True)

data_unicos['IsTheyBusinessperson'] = data_unicos['IsTheyBusinessperson'].replace({0: 'Nonentrepreneur', 1: 'Entrepreneur'})

data.rename(columns={'FORMA_EVASAO':'FINAL_STATUS'}, inplace=True)
data_unicos.rename(columns={'FORMA_EVASAO':'FINAL_STATUS'}, inplace=True)

data_modelo = data_unicos[['ingresso_atual', 'MEDIA_FINAL', 'CR_ATUAL', 'CR_NO_PERIODO', 'FINAL_STATUS', 'SEXO', 'IsTheyBusinessperson', 'Categoria', 'GPA1', 'GPA2', 'GPA3', 'GPA4','grade_programming1', 'grade_programming2', 'grade_basic_math','grade_calculus1', 'grade_linear_algebra', 'employee_student']]
categorical_columns = ['ingresso_atual', 'FINAL_STATUS', 'Categoria', 'IsTheyBusinessperson', 'SEXO', 'employee_student']
numerical_columns = ['GPA1', 'GPA2', 'GPA3', 'GPA4', 'grade_programming1', 'grade_programming2', 'grade_basic_math', 'grade_calculus1', 'grade_linear_algebra']

le = LabelEncoder()

# Transformando e salvando os encoders
data_modelo['ingresso_atual'] = le.fit_transform(data_modelo['ingresso_atual'])
joblib.dump(le, 'label_encoder_ingresso_atual.pkl')
files.download(f'label_encoder_ingresso_atual.pkl')

data_modelo['FINAL_STATUS'] = le.fit_transform(data_modelo['FINAL_STATUS'])


data_modelo['Categoria'] = le.fit_transform(data_modelo['Categoria'])
joblib.dump(le, 'label_encoder_Categoria.pkl')
files.download(f'label_encoder_Categoria.pkl')

data_modelo['IsTheyBusinessperson'] = le.fit_transform(data_modelo['IsTheyBusinessperson'])
joblib.dump(le, 'label_encoder_IsTheyBusinessperson.pkl')
files.download(f'label_encoder_IsTheyBusinessperson.pkl')

data_modelo['SEXO'] = le.fit_transform(data_modelo['SEXO'])
joblib.dump(le, 'label_encoder_SEXO.pkl')
files.download(f'label_encoder_SEXO.pkl')

data_modelo['employee_student'] = le.fit_transform(data_modelo['employee_student'])
joblib.dump(le, 'label_encoder_employee_student.pkl')
files.download(f'label_encoder_employee_student.pkl')

data_modelo

from sklearn.preprocessing import LabelEncoder
import joblib
from google.colab import files
'''
# Suponha que 'data_modelo' é o seu DataFrame de treinamento
colunas_categoricas = ['ingresso_atual', 'FINAL_STATUS', 'Categoria', 'IsTheyBusinessperson', 'SEXO', 'employee_student'] # Changed tuple to list
label_encoders = {}
for col in categorical_columns:
    le = LabelEncoder()
    # Encode the 'data_modelo' DataFrame, not 'data'
    data_modelo[col] = le.fit_transform(data_modelo[col])
    label_encoders[col] = le
    joblib.dump(le, f'label_encoder_{col}.pkl')
    files.download(f'label_encoder_{col}.pkl')

# Separar features e target
X = data_modelo  [['ingresso_atual', 'GPA1', 'GPA2','GPA3', 'GPA4', 'IsTheyBusinessperson', 'Categoria', 'SEXO','grade_programming1', 'grade_programming2', 'grade_basic_math','grade_calculus1', 'grade_linear_algebra','employee_student']]
y = data_modelo  ['FINAL_STATUS']

# Remove 'FINAL_STATUS' from categorical columns for the transformer
categorical_columns_for_transformer = ['ingresso_atual', 'Categoria', 'IsTheyBusinessperson', 'SEXO', 'employee_student']
'''

categorical_columns_for_transformer = ['ingresso_atual', 'Categoria', 'IsTheyBusinessperson', 'SEXO', 'employee_student']

preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_columns),
        ('cat', 'passthrough', categorical_columns_for_transformer)
    ]
)

pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', HistGradientBoostingClassifier())
])

X = data_modelo[numerical_columns + categorical_columns]
y = data_modelo['FINAL_STATUS']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

pipeline.fit(X_train , y_train)

# Salvar o pipeline inteiro
joblib.dump(pipeline, 'model4GPA.pkl')
files.download('model4GPA.pkl')

y_pred = pipeline.predict(X_test)

# Avalie o desempenho do modelo
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)
print("Model accuracy:", accuracy)
print("Report:\n", report)

X

# prompt: Gere uma instância aleatória para testar a previsão de pipeline

import random

# Generate random indices within the test data range
random_indices = random.sample(range(len(X_test)), 10)

# Select random instances from X_test based on the generated indices
random_instances = X_test.iloc[random_indices]

# Predict the target values for the selected instances
predicted_values = pipeline.predict(random_instances)

# Print the actual and predicted values
print("Actual values:", y_test.iloc[random_indices])
print("Predicted values:", predicted_values)